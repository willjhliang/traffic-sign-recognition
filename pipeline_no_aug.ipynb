{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/willjhliang/traffic-sign-recognition/blob/main/pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wniuiSo3XwSa"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRrDti8n2Vw8"
      },
      "outputs": [],
      "source": [
        "# Download dataset from github repo\n",
        "!git clone --quiet https://github.com/willjhliang/traffic-sign-recognition.git\n",
        "!mv traffic-sign-recognition/* .\n",
        "!rm -r traffic-sign-recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDwc2e3-4pvC"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.base import clone\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils import data\n",
        "import torchvision\n",
        "\n",
        "from constants import K, S, class_size, validation_ratio, random_seed\n",
        "from data import load_data, consolidate_data, split_validation, visualize_data, compare_class_dist\n",
        "from augment import augment_dataset, visualize_augmentation\n",
        "from dimensionality_reduction import run_pca, visualize_pca, visualize_pca_per_channel\n",
        "from torch_utils import load_torch_data, train_model, evaluate_model\n",
        "from evaluation import generate_confusion_matrix, get_classification_report, generate_class_comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaaChV3Way94"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Br0-GXCA4rts"
      },
      "outputs": [],
      "source": [
        "train_data = load_data('data/filtered_images/train')\n",
        "test_data = load_data('data/filtered_images/test')\n",
        "labels = pd.read_csv(\"data/filtered_labels.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeVxBPI864JY"
      },
      "outputs": [],
      "source": [
        "visualize_data(train_data)\n",
        "compare_class_dist(train_data, test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTT4G6q63fp6"
      },
      "outputs": [],
      "source": [
        "X_train, X_train_flattened, y_train = consolidate_data(train_data)\n",
        "X_test, X_test_flattened, y_test = consolidate_data(test_data)\n",
        "\n",
        "print(f'X_train shape: {X_train.shape}')\n",
        "print(f'X_train_flattened shape: {X_train_flattened.shape}')\n",
        "print(f'X_test shape: {X_test.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stcaq1MfBJJb"
      },
      "outputs": [],
      "source": [
        "X_train_pca, X_test_pca, pca = run_pca(X_train_flattened, X_test_flattened)\n",
        "visualize_pca(pca)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUuXolGt5JZ-"
      },
      "source": [
        "# Models\n",
        "\n",
        "The following is a set of models we run on the data. Starting with the most simple baseline logistic regression, we move toward more complex models.\n",
        "1. Logistic Regression\n",
        "2. K-Nearest Neighbors\n",
        "3. Adaboost\n",
        "4. Kernelized SVM\n",
        "5. Dense Neural Network\n",
        "6. Convolutional Neural Network\n",
        "7. Transfer Learning Resnet18, VGG16, EfficientNet, and Vision Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgSsZgmhjr5T"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoQq0QNcX4T6"
      },
      "outputs": [],
      "source": [
        "def logistic_regression(X_train_full, y_train_full, X_test, y_test):\n",
        "    X_train, X_val, y_train, y_val = split_validation(X_train_full, y_train_full)\n",
        "\n",
        "    C_values = [0.01, 0.1, 1, 10, 100]\n",
        "    best_C = -1\n",
        "    best_acc = 0\n",
        "\n",
        "    accs = []\n",
        "    for c in tqdm(C_values, leave=False):\n",
        "        model = LogisticRegression(\n",
        "            penalty='l2',\n",
        "            C=c,\n",
        "            multi_class = 'multinomial',\n",
        "            max_iter=1000\n",
        "        )\n",
        "        model.fit(X_train, y_train)\n",
        "        acc = model.score(X_val, y_val)\n",
        "        accs.append(acc)\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_C = c\n",
        "\n",
        "    plt.plot(accs)\n",
        "    plt.xticks(list(range(len(accs))), [str(c) for c in C_values])\n",
        "    plt.show()\n",
        "    print(f'Optimal C: {best_C}')\n",
        "\n",
        "    model = LogisticRegression(\n",
        "        penalty='l2',\n",
        "        C=best_C,\n",
        "        multi_class = 'multinomial',\n",
        "        max_iter=1000\n",
        "    )\n",
        "    model.fit(X_train_full, y_train_full)\n",
        "\n",
        "    return model.predict(X_test), model.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WmDtprV5NqM"
      },
      "source": [
        "## K-Nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GokJxe4KGJz_"
      },
      "outputs": [],
      "source": [
        "kf = KFold(n_splits=5)\n",
        "\n",
        "\n",
        "def evaluate_kfold(model_base, X_train, y_train):\n",
        "    \"\"\"Evaluates the given model with K-Fold cross validation.\"\"\"\n",
        "    total_acc = 0\n",
        "    for train_index, val_index in kf.split(X_train): # Iterate through folds\n",
        "       # Split data into training data and validation data\n",
        "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        " \n",
        "        # Train model\n",
        "        model = clone(model_base)\n",
        "        model.fit(X_train_fold, y_train_fold)\n",
        "        total_acc += model.score(X_val_fold, y_val_fold)\n",
        "       \n",
        "    avg_acc = total_acc / 5\n",
        "    return avg_acc\n",
        "\n",
        "\n",
        "def knn(X_train, y_train, X_test, y_test):\n",
        "    k_values = [1, 3, 5, 7, 9, 11, 13, 15]\n",
        "    best_k = -1\n",
        "    best_acc = 0\n",
        "\n",
        "    accs = []\n",
        "    for k_neighbors in tqdm(k_values, leave=False):\n",
        "        avg_acc = evaluate_kfold(KNeighborsClassifier(n_neighbors = k_neighbors), X_train, y_train)\n",
        "        accs.append(avg_acc)\n",
        "        if avg_acc > best_acc:\n",
        "            best_acc = avg_acc\n",
        "            best_k = k_neighbors\n",
        " \n",
        "    plt.plot(k_values, accs)\n",
        "    plt.show()\n",
        "    print(f\"Optimal k: {best_k}\")\n",
        "    \n",
        "    model = KNeighborsClassifier(n_neighbors=best_k)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    return model.predict(X_test), model.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1sX4gyWji8A"
      },
      "source": [
        "## Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdmToVHvYAvN"
      },
      "outputs": [],
      "source": [
        "def adaboost(X_train_full, y_train_full, X_test, y_test):\n",
        "    X_train, X_val, y_train, y_val = split_validation(X_train_full, y_train_full)\n",
        "\n",
        "    learning_rates = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
        "    best_lr = -1\n",
        "    best_acc = 0\n",
        "\n",
        "    accs = []\n",
        "    for lr in tqdm(learning_rates, leave=False):\n",
        "        model = AdaBoostClassifier(\n",
        "            DecisionTreeClassifier(max_depth=1),\n",
        "            n_estimators=200,\n",
        "            algorithm=\"SAMME.R\",\n",
        "            learning_rate=lr,\n",
        "            random_state=random_seed\n",
        "        )\n",
        "        model.fit(X_train, y_train)\n",
        "        acc = model.score(X_val, y_val)\n",
        "        accs.append(acc)\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_lr = lr\n",
        "  \n",
        "    plt.plot(accs)\n",
        "    plt.xticks(list(range(len(accs))), [str(lr) for lr in learning_rates])\n",
        "    plt.show()\n",
        "    print(f'Optimal learning rate: {best_lr}')\n",
        "    \n",
        "    model = AdaBoostClassifier(\n",
        "        DecisionTreeClassifier(max_depth=1),\n",
        "        n_estimators=200,\n",
        "        algorithm=\"SAMME.R\",\n",
        "        learning_rate=lr,\n",
        "        random_state=random_seed\n",
        "    )\n",
        "    model.fit(X_train_full, y_train_full)\n",
        " \n",
        "    return model.predict(X_test), model.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17znCaqJ82C4"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJagudza83b6"
      },
      "outputs": [],
      "source": [
        "def xgboost(X_train_full, y_train_full, X_test, y_test):\n",
        "    X_train, X_val, y_train, y_val = split_validation(X_train_full, y_train_full)\n",
        "\n",
        "    learning_rates = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
        "    best_lr = -1\n",
        "    best_acc = 0\n",
        " \n",
        "    accs = []\n",
        "    for lr in tqdm(learning_rates, leave=False):\n",
        "        model = xgb.XGBClassifier(n_estimators=200, max_depth=1, learning_rate=0.1, objective='multi:softmax', booster='gbtree', num_classes=K)\n",
        "        model.fit(X_train, y_train)\n",
        "        acc = model.score(X_val, y_val)\n",
        "        accs.append(acc)\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_lr = lr\n",
        "     \n",
        "    plt.plot(accs)\n",
        "    plt.xticks(list(range(len(accs))), [str(lr) for lr in learning_rates])\n",
        "    plt.show()\n",
        "    print(f'Optimal learning rate: {best_lr}')\n",
        "  \n",
        "    model = xgb.XGBClassifier(n_estimators=200, max_depth=1, learning_rate=lr, objective='multi:softmax', booster='gbtree', num_classes=K)\n",
        "    model.fit(X_train_full, y_train_full)\n",
        "\n",
        "    return model.predict(X_test), model.score(X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBUqSumgjuwY"
      },
      "source": [
        "## Kernelized SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCLRPjXyYJOr"
      },
      "outputs": [],
      "source": [
        "def kernel_svm(X_train_full, y_train_full, X_test, y_test):\n",
        "    X_train, X_val, y_train, y_val = split_validation(X_train_full, y_train_full)\n",
        "\n",
        "    kernels = ['linear', 'poly', 'rbf']\n",
        "    C_values = [0.01, 0.1, 1, 10, 100]\n",
        "    best_kernel = ''\n",
        "    best_C = -1\n",
        "    best_acc = 0\n",
        "\n",
        "    accs = {}\n",
        "    for kernel in kernels:\n",
        "        accs[kernel] = []\n",
        "    for kernel, c in tqdm(itertools.product(kernels, C_values), leave=False):\n",
        "        model = SVC(kernel=kernel, C=c)\n",
        "        model.fit(X_train, y_train)\n",
        "        acc = model.score(X_val, y_val)\n",
        "        accs[kernel].append(acc)\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_C = c\n",
        "            best_kernel = kernel\n",
        "    \n",
        "    best_accs = [max(accs[kernel]) for kernel in kernels]\n",
        "    plt.bar(kernels, best_accs)\n",
        "    plt.xticks(list(range(len(best_accs))), kernels)\n",
        "    plt.show()\n",
        "    print(f'Optimal kernel: {best_kernel}')\n",
        "\n",
        "    model = SVC(kernel=best_kernel, C=best_C)\n",
        "    model.fit(X_train_full, y_train_full)\n",
        "\n",
        "    return model.predict(X_test), model.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPCS7NeYjxn1"
      },
      "source": [
        "## Dense Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXZT0kN1c0JU"
      },
      "outputs": [],
      "source": [
        "class NN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(32 * 32 * 3, 128)\n",
        "        self.layer2 = nn.Linear(128, 64)\n",
        "        self.out_layer = nn.Linear(64, K)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.relu(self.layer2(x))\n",
        "        x = self.out_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsattGC-jzYw"
      },
      "source": [
        "## Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CB0H8YxKTnl"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.conv_1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm_1 = nn.BatchNorm2d(32)\n",
        "        self.conv_2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
        "        self.conv_3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
        "        self.conv_4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm_4 = nn.BatchNorm2d(64)\n",
        "        self.dropout_1 = nn.Dropout(0.5)\n",
        "        self.conv_5 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm_5 = nn.BatchNorm2d(64)\n",
        "        self.conv_6 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm_6 = nn.BatchNorm2d(64)\n",
        "        self.dropout_2 = nn.Dropout(0.5)\n",
        "        self.linear_1 = nn.Linear(4 * 4 * 64, 128)\n",
        "        self.dropout_3 = nn.Dropout(0.25)\n",
        "        self.linear_2 = nn.Linear(128, K)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.batch_norm_1(self.conv_1(x)))\n",
        "        x = self.relu(self.batch_norm_2(self.conv_2(x)))\n",
        "        x = self.max_pool2d(x)\n",
        "        x = self.relu(self.batch_norm_3(self.conv_3(x)))\n",
        "        x = self.relu(self.batch_norm_4(self.conv_4(x)))\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.max_pool2d(x)\n",
        "        x = self.relu(self.batch_norm_5(self.conv_5(x)))\n",
        "        x = self.relu(self.batch_norm_6(self.conv_6(x)))\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.max_pool2d(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.relu(self.linear_1(x))\n",
        "        x = self.dropout_3(x)\n",
        "        x = self.linear_2(x)\n",
        "        return x"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jI9lT-q-kteU"
      },
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCCV5sIrH-Rq"
      },
      "outputs": [],
      "source": [
        "def Resnet():\n",
        "    model = torchvision.models.resnet18(pretrained=True)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, K)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Xq-iQwNfbKq"
      },
      "outputs": [],
      "source": [
        "def VGG16():\n",
        "    model = torchvision.models.vgg16(pretrained=True)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    num_ftrs = model.classifier[-1].in_features\n",
        "    model.classifier[-1] = nn.Linear(num_ftrs, K)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDWWGFp6kW8c"
      },
      "outputs": [],
      "source": [
        "def EfficientNet():\n",
        "    model = torchvision.models.efficientnet_b0(pretrained=True)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    num_ftrs = model.classifier[-1].in_features\n",
        "    model.classifier[-1] = nn.Linear(num_ftrs, K)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxTjUA2PYJoR"
      },
      "outputs": [],
      "source": [
        "class UpscaleDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, transform):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.numpy()\n",
        "        img = self.transform(torch.from_numpy(self.X[idx].astype(np.float32)))\n",
        "        label = torch.tensor(self.y[idx])\n",
        "\n",
        "        return img, label\n",
        "\n",
        "\n",
        "def load_vit_data(X_train, y_train, X_test, y_test):\n",
        "    X_train, X_val, y_train, y_val = split_validation(X_train, y_train)\n",
        "    transform = torchvision.transforms.Resize((224, 224))\n",
        "    train_set = UpscaleDataset(X_train, y_train, transform)\n",
        "    val_set = UpscaleDataset(X_val, y_val, transform)\n",
        "    test_set = UpscaleDataset(X_test, y_test, transform)\n",
        "    train_loader = data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "    val_loader = data.DataLoader(val_set, batch_size=32, shuffle=True)\n",
        "    test_loader = data.DataLoader(test_set, batch_size=32, shuffle=True)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def VisionTransformer():\n",
        "    model = torchvision.models.vit_b_16(pretrained=True)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    num_ftrs = model.heads[-1].in_features\n",
        "    model.heads[-1] = nn.Linear(num_ftrs, K)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLYfefMU_GtW"
      },
      "source": [
        "# Training and Evaluation\n",
        "We now run all the models defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zp1KiWpzZXF5"
      },
      "outputs": [],
      "source": [
        "print('========== Logistic Regression ==========')\n",
        "y_pred_log, acc = logistic_regression(X_train_flattened, y_train, X_test_flattened, y_test)\n",
        "print(f'Test Accuracy: {acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UutFm3xnZsFq"
      },
      "outputs": [],
      "source": [
        "log_report, log_df = get_classification_report(y_test, y_pred_log, labels)\n",
        "generate_class_comparison(log_report, 'f1-score', labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcuHmemjqoLg"
      },
      "outputs": [],
      "source": [
        "print('========== Logistic Regression (PCA) ==========')\n",
        "y_pred_log, acc = logistic_regression(X_train_pca, y_train, X_test_pca, y_test)\n",
        "print(f'Test Accuracy: {acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4FX1-LeZtSb"
      },
      "outputs": [],
      "source": [
        "log_report, log_df = get_classification_report(y_test, y_pred_log, labels)\n",
        "generate_class_comparison(log_report, 'f1-score', labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvxEFB-3iciz"
      },
      "outputs": [],
      "source": [
        "print('========== KNN ==========')\n",
        "y_pred_knn, acc = knn(X_train_flattened, y_train, X_test_flattened, y_test)\n",
        "print(f'Test Accuracy: {acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQri17VCZuXQ"
      },
      "outputs": [],
      "source": [
        "knn_reportdict, knn_df = get_classification_report(y_test, y_pred_knn, labels)\n",
        "generate_class_comparison(knn_reportdict, 'f1-score', labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6g8G3SdJ_LZv"
      },
      "outputs": [],
      "source": [
        "print('========== KNN (PCA) ==========')\n",
        "y_pred_knnpca, acc = knn(X_train_pca, y_train, X_test_pca, y_test)\n",
        "print(f'Test Accuracy: {acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dELOgQ0uZvs7"
      },
      "outputs": [],
      "source": [
        "knnpca_reportdict, knnpca_df = get_classification_report(y_test, y_pred_knnpca, labels)\n",
        "generate_class_comparison(knnpca_reportdict, 'f1-score', labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_N92jyr_QG0"
      },
      "outputs": [],
      "source": [
        "print('========== Adaboost (PCA) ==========')\n",
        "y_pred_ada, acc = adaboost(X_train_pca, y_train, X_test_pca, y_test)\n",
        "print(f'Test Accuracy: {acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfIJ_fADZxFk"
      },
      "outputs": [],
      "source": [
        "ada_reportdict, ada_df = get_classification_report(y_test, y_pred_ada, labels)\n",
        "generate_class_comparison(ada_reportdict, 'f1-score', labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Qfi7EfEZKgB"
      },
      "outputs": [],
      "source": [
        "print('========== XGBoost (PCA) ==========')\n",
        "y_pred_xgb, acc = xgboost(X_train_pca, y_train, X_test_pca, y_test)\n",
        "print(f'Test Accuracy: {acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "503ydhEwZyJ9"
      },
      "outputs": [],
      "source": [
        "xgb_reportdict, xbg_df = get_classification_report(y_test, y_pred_xgb, labels)\n",
        "generate_class_comparison(xgb_reportdict, 'f1-score', labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w15JpLCYE07O"
      },
      "outputs": [],
      "source": [
        "print('========== Kernelized SVM ==========')\n",
        "y_pred_svm, acc = kernel_svm(X_train_flattened, y_train, X_test_flattened, y_test)\n",
        "print(f'Test Accuracy: {acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMubKB76ZzI0"
      },
      "outputs": [],
      "source": [
        "svm_reportdict, svm_df = get_classification_report(y_test, y_pred_svm, labels)\n",
        "generate_class_comparison(svm_reportdict, 'f1-score', labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAElP9LLniup"
      },
      "outputs": [],
      "source": [
        "print('========== Kernelized SVM (PCA) ==========')\n",
        "y_pred_svm, acc = kernel_svm(X_train_pca, y_train, X_test_pca, y_test)\n",
        "print(f'Test Accuracy: {acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7GxC49SZ0OW"
      },
      "outputs": [],
      "source": [
        "svm_reportdict, svm_df = get_classification_report(y_test, y_pred_svm, labels)\n",
        "generate_class_comparison(svm_reportdict, 'f1-score', labels)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:05:16) \n[Clang 12.0.1 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "d53f40f7b23e64941bbbe7d59a7d348ea20d4e2d35ce7e2b267b19a1ca57345e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
