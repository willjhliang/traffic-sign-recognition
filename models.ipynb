{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/willjhliang/traffic-sign-recognition/blob/main/models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "wniuiSo3XwSa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRrDti8n2Vw8"
      },
      "outputs": [],
      "source": [
        "# Download dataset from github repo\n",
        "!git clone --quiet https://github.com/willjhliang/traffic-sign-recognition.git\n",
        "!mv traffic-sign-recognition/data .\n",
        "!rm -r traffic-sign-recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDwc2e3-4pvC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from copy import deepcopy\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.base import clone\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "import xgboost as xgb\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils import data\n",
        "from torch import Tensor\n",
        "import torchvision\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report\n",
        "from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8auRbcGP5jJJ"
      },
      "outputs": [],
      "source": [
        "K = 36                  # Number of classes\n",
        "S = 32                  # Size of image, dimension is (s, s, 3)\n",
        "class_size = 320        # Number of images per class\n",
        "validation_ratio = 0.1  # Proportion of training data to set aside for validation\n",
        "\n",
        "random_seed = 19104     # Seed all random operations to ensure reproducibility\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaaChV3Way94"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gr29Pwh625Jl"
      },
      "outputs": [],
      "source": [
        "def load_data(datapath):\n",
        "    \"\"\"Loads images from files and performs basic pre-processing.\"\"\"\n",
        "    data = {}\n",
        "    for k in range(K):\n",
        "        data[k] = []\n",
        "\n",
        "    for f in os.listdir(datapath):\n",
        "        k = int(f[:3])  # Get label from filename\n",
        "        img = Image.open(os.path.join(datapath, f))\n",
        "        img = np.asarray(img) / 255  # Set pixel values to [0, 1]\n",
        "        if len(data[k]) < class_size:\n",
        "            data[k].append(img)\n",
        "    random.shuffle(data[k])\n",
        "    \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Br0-GXCA4rts"
      },
      "outputs": [],
      "source": [
        "train_data = load_data('data/filtered_images/train')\n",
        "test_data = load_data('data/filtered_images/test')\n",
        "labels = pd.read_csv(\"data/filtered_labels.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjD_ep2c5HUg"
      },
      "source": [
        "## Data Exploration\n",
        "\n",
        "We'll explore the dataset by displaying example images from each class. We also plot the number of images belonging to each class and find that it's extremely variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeVxBPI864JY"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(6, 10, figsize=(15, 8))\n",
        "for k, (i, j) in itertools.zip_longest(range(K), list(itertools.product(range(6), range(10))), fillvalue=-1):\n",
        "    axs[i,j].axis('off')\n",
        "    if k >= 0:\n",
        "        axs[i,j].imshow(train_data[k][0])  # Visualize the first image of every class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKSJPEi5s0si"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(6, 10, figsize=(15, 8))\n",
        "for k, (i, j) in itertools.zip_longest(range(K), list(itertools.product(range(6), range(10))), fillvalue=-1):\n",
        "    axs[i,j].axis('off')\n",
        "    if k >= 0 and len(test_data[k]) > 0:\n",
        "        axs[i,j].imshow(test_data[k][0])  # Visualize the first image of every class in the testing set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3rniKpZ9gNo"
      },
      "outputs": [],
      "source": [
        "train_class_dist = [len(train_data[k]) for k in range(K)]\n",
        "test_class_dist = [len(test_data[k]) for k in range(K)]\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
        "axs[0].bar(list(range(K)), train_class_dist)\n",
        "axs[1].bar(list(range(K)), test_class_dist);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwHmRzn_WERd"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "To preprocess our data, we'll first augment the classes with fewer image examples. Our augmentation scheme includes cropping, rotation, and brightness changes; note that we don't apply any flips since it violates the symbols on traffic signs.\n",
        "\n",
        "After augmentation, we reshape the data to an array format and store labels as integers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETRb3zMX869y"
      },
      "outputs": [],
      "source": [
        "def center_crop(img, center_percentage):\n",
        "    \"\"\"Crops out edges of an image, leaving the center.\"\"\"\n",
        "    width, height, _ = img.shape\n",
        "    width_offset = int(width * (1 - center_percentage) / 2)\n",
        "    height_offset = int(height * (1 - center_percentage) / 2)\n",
        "    img = img[width_offset:width-width_offset, height_offset:height-height_offset]\n",
        "    return img\n",
        "\n",
        "\n",
        "def rotate_img(img, angle):\n",
        "    \"\"\"Rotates an image and replaces empty space with black.\"\"\"\n",
        "    height, width, _ = img.shape\n",
        "    center_x, center_y = (width // 2, height // 2)\n",
        "\n",
        "    rot_mat = cv2.getRotationMatrix2D((center_x, center_y), angle, 1.0)\n",
        "    cos = np.abs(rot_mat[0, 0])\n",
        "    sin = np.abs(rot_mat[0, 1])\n",
        "\n",
        "    new_width = int((height * sin) + (width * cos))\n",
        "    new_height = int((height * cos) + (width * sin))\n",
        "    rot_mat[0, 2] += (new_width / 2) - center_x\n",
        "    rot_mat[1, 2] += (new_height / 2) - center_y\n",
        "\n",
        "    img = cv2.warpAffine(img, rot_mat, (new_width, new_height))\n",
        "    img = cv2.resize(img, (width, height))\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def shift_brightness(img, shift):\n",
        "    \"\"\"Adjusts brightness of all pixels in image.\"\"\"\n",
        "    img = np.clip(img + shift, 0, 1)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0LV8uZsCB0_"
      },
      "outputs": [],
      "source": [
        "def augment_img(img):\n",
        "    \"\"\"Augments image with rotation, cropping, and brightness shifts.\"\"\"\n",
        "    rot_angle = random.randint(-20, 20)\n",
        "    crop_center_percentage = random.randint(70, 90) / 100\n",
        "    crop_center_percentage = 0.8\n",
        "    brightness_shift = random.randint(-10, 10) / 100\n",
        "\n",
        "    img = rotate_img(img, rot_angle)\n",
        "    # img = center_crop(img, crop_center_percentage)\n",
        "    # img = shift_brightness(img, brightness_shift)\n",
        "    img = center_crop(img, 0.8)\n",
        "\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aslUcb0wNSAI"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(6, 10, figsize=(15, 8))\n",
        "for k, (i, j) in itertools.zip_longest(range(K), list(itertools.product(range(6), range(10))), fillvalue=-1):\n",
        "    axs[i,j].axis('off')\n",
        "    if k >= 0:\n",
        "        img = augment_img(train_data[k][-1])\n",
        "        axs[i,j].imshow(augment_img(img))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG-NpBFR8hgP"
      },
      "outputs": [],
      "source": [
        "max_k_size = max([len(train_data[k]) for k in range(K)])\n",
        "for k in range(K):\n",
        "    k_size = len(train_data[k])\n",
        "    for i in range(max_k_size - k_size):  # Add augmented images until we have class_size images\n",
        "        train_data[k].append(augment_img(train_data[k][i % k_size]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nt5sG5QiHtzk"
      },
      "outputs": [],
      "source": [
        "aug_class_dist = [len(train_data[k]) for k in range(K)]\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
        "axs[0].bar(list(range(K)), train_class_dist)\n",
        "axs[1].bar(list(range(K)), aug_class_dist);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UVlLK8c3HXn"
      },
      "outputs": [],
      "source": [
        "def prepare_data(data):\n",
        "    \"\"\"Converts image-label data from map to numpy arrays.\"\"\"\n",
        "    X = []\n",
        "    y = []\n",
        "    for k in range(K):\n",
        "        for i in data[k]:\n",
        "            i = cv2.resize(i, (S, S))\n",
        "            X.append(np.swapaxes(i, 0, -1))\n",
        "            y.append(k)\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    \n",
        "    shuffled_indices = np.random.permutation(len(X))\n",
        "    X = X[shuffled_indices]\n",
        "    y = y[shuffled_indices]\n",
        "    X_flattened = np.reshape(X, (X.shape[0], -1))\n",
        "    \n",
        "    return X, X_flattened, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTT4G6q63fp6"
      },
      "outputs": [],
      "source": [
        "X_train, X_train_flattened, y_train = prepare_data(train_data)\n",
        "X_test, X_test_flattened, y_test = prepare_data(test_data)\n",
        "print(f'X_train shape: {X_train.shape}')\n",
        "print(f'X_train_flattened shape: {X_train_flattened.shape}')\n",
        "print(f'X_test shape: {X_test.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27w1N04HdH8f"
      },
      "outputs": [],
      "source": [
        "def get_validation(X_train, y_train):\n",
        "    \"\"\"Splits training data into train and validation sets. Used in models below.\"\"\"\n",
        "    val_split = int(X_train.shape[0] * validation_ratio)\n",
        "    X_train, X_val = X_train[val_split:], X_train[:val_split]\n",
        "    y_train, y_val = y_train[val_split:], y_train[:val_split]\n",
        "    return X_train, X_val, y_train, y_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXEGZ3KE_adb"
      },
      "source": [
        "## Dimensionality Reduction\n",
        "\n",
        "With 32 x 32 features, our models below take a long time to converge. We try both PCA and neural network autoencoders to reduce the feature space before training our sklearn models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLwF2wzM_wyH"
      },
      "outputs": [],
      "source": [
        "covar_matrix = PCA(n_components=min(X_train.shape[0], 32*32))\n",
        "covar_matrix.fit(X_train_flattened)\n",
        "variance = covar_matrix.explained_variance_ratio_\n",
        "var=np.cumsum(np.round(covar_matrix.explained_variance_ratio_, decimals=3)*100)\n",
        "plt.plot(var[:300]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stcaq1MfBJJb"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=130)\n",
        "pca.fit(X_train_flattened)\n",
        "X_train_pca = pca.transform(X_train_flattened)\n",
        "X_test_pca = pca.transform(X_test_flattened)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(3, 4, figsize=(5, 4),\n",
        "    subplot_kw={'xticks':[], 'yticks':[]},\n",
        "    gridspec_kw=dict(hspace=0.1, wspace=0.1)\n",
        ")\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "   img = pca.components_[i].reshape(3, 32, 32)\n",
        "   min_val, max_val = np.min(img), np.max(img)\n",
        "   img = (img - min_val) / (max_val - min_val)\n",
        "   img = np.swapaxes(img, 0, -1)\n",
        "   ax.imshow(img)"
      ],
      "metadata": {
        "id": "tb7AN88FapK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pca_on_channel(channel):\n",
        "    X_train_channel = np.array([i.flatten() for i in X_train[:, channel, :, :]])\n",
        "    ret = PCA(n_components=130)\n",
        "    ret.fit(X_train_channel)\n",
        "    return ret\n",
        " \n",
        "fig, axes = plt.subplots(3, 8, figsize=(9, 4),\n",
        "    subplot_kw={'xticks':[], 'yticks':[]},\n",
        "    gridspec_kw=dict(hspace=0.1, wspace=0.1)\n",
        ")\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(pca_on_channel(0).components_[i].reshape(32, 32))\n",
        " \n",
        "fig, axes = plt.subplots(3, 8, figsize=(9, 4),\n",
        "    subplot_kw={'xticks':[], 'yticks':[]},\n",
        "    gridspec_kw=dict(hspace=0.1, wspace=0.1)\n",
        ")\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(pca_on_channel(1).components_[i].reshape(32, 32))\n",
        "    \n",
        "fig, axes = plt.subplots(3, 8, figsize=(9, 4),\n",
        "    subplot_kw={'xticks':[], 'yticks':[]},\n",
        "    gridspec_kw=dict(hspace=0.1, wspace=0.1)\n",
        ")\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(pca_on_channel(2).components_[i].reshape(32, 32))"
      ],
      "metadata": {
        "id": "RFCqW5QubPCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUuXolGt5JZ-"
      },
      "source": [
        "# Models\n",
        "\n",
        "The following is a set of models we run on the data. Starting with the most simple baseline logistic regression, we move toward more complex models.\n",
        "1. Logistic Regression\n",
        "2. K-Nearest Neighbors\n",
        "3. Adaboost\n",
        "4. Kernelized SVM\n",
        "5. Dense Neural Network\n",
        "6. Convolutional Neural Network\n",
        "7. Transfer Learning CNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgSsZgmhjr5T"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoQq0QNcX4T6"
      },
      "outputs": [],
      "source": [
        "def logistic_regression(X_train_full, y_train_full, X_test, y_test):\n",
        "    X_train, X_val, y_train, y_val = get_validation(X_train_full, y_train_full)\n",
        "\n",
        "    C_values = [0.01, 0.1, 1, 10, 100]\n",
        "    best_C = -1\n",
        "    best_acc = 0\n",
        "\n",
        "    accs = []\n",
        "    for c in tqdm(C_values, leave=False):\n",
        "        model = LogisticRegression(\n",
        "            penalty='l2',\n",
        "            C=c,\n",
        "            multi_class = 'multinomial',\n",
        "            max_iter=1000\n",
        "        )\n",
        "        model.fit(X_train, y_train)\n",
        "        acc = model.score(X_val, y_val)\n",
        "        accs.append(acc)\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_C = c\n",
        "\n",
        "    plt.plot(accs)\n",
        "    plt.xticks(list(range(len(accs))), [str(c) for c in C_values])\n",
        "    plt.show()\n",
        "    print(f'Optimal C: {best_C}')\n",
        "\n",
        "    model = LogisticRegression(\n",
        "        penalty='l2',\n",
        "        C=best_C,\n",
        "        multi_class = 'multinomial',\n",
        "        max_iter=1000\n",
        "    )\n",
        "    model.fit(X_train_full, y_train_full)\n",
        "\n",
        "    return model.predict(X_test), model.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WmDtprV5NqM"
      },
      "source": [
        "## K-Nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GokJxe4KGJz_"
      },
      "outputs": [],
      "source": [
        "kf = KFold(n_splits=5)\n",
        "\n",
        "\n",
        "def evaluate_kfold(model_base, X_train, y_train):\n",
        "    \"\"\"Evaluates the given model with K-Fold cross validation.\"\"\"\n",
        "    total_acc = 0\n",
        "    for train_index, val_index in kf.split(X_train): # Iterate through folds\n",
        "       # Split data into training data and validation data\n",
        "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        " \n",
        "        # Train model\n",
        "        model = clone(model_base)\n",
        "        model.fit(X_train_fold, y_train_fold)\n",
        "        total_acc += model.score(X_val_fold, y_val_fold)\n",
        "       \n",
        "    avg_acc = total_acc / 5\n",
        "    return avg_acc\n",
        "\n",
        "\n",
        "def knn(X_train, y_train, X_test, y_test):\n",
        "    k_values = [1, 3, 5, 7, 9, 11, 13, 15]\n",
        "    best_k = -1\n",
        "    best_acc = 0\n",
        "\n",
        "    accs = []\n",
        "    for k_neighbors in tqdm(k_values, leave=False):\n",
        "        avg_acc = evaluate_kfold(KNeighborsClassifier(n_neighbors = k_neighbors), X_train, y_train)\n",
        "        accs.append(avg_acc)\n",
        "        if avg_acc > best_acc:\n",
        "            best_acc = avg_acc\n",
        "            best_k = k_neighbors\n",
        " \n",
        "    plt.plot(k_values, accs)\n",
        "    plt.show()\n",
        "    print(f\"Optimal k: {best_k}\")\n",
        "    \n",
        "    model = KNeighborsClassifier(n_neighbors=best_k)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    return model.predict(X_test), model.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1sX4gyWji8A"
      },
      "source": [
        "## Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdmToVHvYAvN"
      },
      "outputs": [],
      "source": [
        "def adaboost(X_train_full, y_train_full, X_test, y_test):\n",
        "    X_train, X_val, y_train, y_val = get_validation(X_train_full, y_train_full)\n",
        "\n",
        "    learning_rates = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
        "    best_lr = -1\n",
        "    best_acc = 0\n",
        "\n",
        "    accs = []\n",
        "    for lr in tqdm(learning_rates, leave=False):\n",
        "        model = AdaBoostClassifier(\n",
        "            DecisionTreeClassifier(max_depth=1),\n",
        "            n_estimators=200,\n",
        "            algorithm=\"SAMME.R\",\n",
        "            learning_rate=lr,\n",
        "            random_state=random_seed\n",
        "        )\n",
        "        model.fit(X_train, y_train)\n",
        "        acc = model.score(X_val, y_val)\n",
        "        accs.append(acc)\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_lr = lr\n",
        "  \n",
        "    plt.plot(accs)\n",
        "    plt.xticks(list(range(len(accs))), [str(lr) for lr in learning_rates])\n",
        "    plt.show()\n",
        "    print(f'Optimal learning rate: {best_lr}')\n",
        "    \n",
        "    model = AdaBoostClassifier(\n",
        "        DecisionTreeClassifier(max_depth=1),\n",
        "        n_estimators=200,\n",
        "        algorithm=\"SAMME.R\",\n",
        "        learning_rate=lr,\n",
        "        random_state=random_seed\n",
        "    )\n",
        "    model.fit(X_train_full, y_train_full)\n",
        " \n",
        "    return model.predict(X_test), model.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17znCaqJ82C4"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJagudza83b6"
      },
      "outputs": [],
      "source": [
        "def xgboost(X_train_full, y_train_full, X_test, y_test):\n",
        "    X_train, X_val, y_train, y_val = get_validation(X_train_full, y_train_full)\n",
        "\n",
        "    learning_rates = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
        "    best_lr = -1\n",
        "    best_acc = 0\n",
        " \n",
        "    accs = []\n",
        "    for lr in tqdm(learning_rates, leave=False):\n",
        "        model = xgb.XGBClassifier(n_estimators=200, max_depth=1, learning_rate=0.1, objective='multi:softmax', booster='gbtree', num_classes=K)\n",
        "        model.fit(X_train, y_train)\n",
        "        acc = model.score(X_val, y_val)\n",
        "        accs.append(acc)\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_lr = lr\n",
        "     \n",
        "    plt.plot(accs)\n",
        "    plt.xticks(list(range(len(accs))), [str(lr) for lr in learning_rates])\n",
        "    plt.show()\n",
        "    print(f'Optimal learning rate: {best_lr}')\n",
        "  \n",
        "    model = xgb.XGBClassifier(n_estimators=200, max_depth=1, learning_rate=lr, objective='multi:softmax', booster='gbtree', num_classes=K)\n",
        "    model.fit(X_train_full, y_train_full)\n",
        "\n",
        "    return model.predict(X_test), model.score(X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBUqSumgjuwY"
      },
      "source": [
        "## Kernelized SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCLRPjXyYJOr"
      },
      "outputs": [],
      "source": [
        "def kernel_svm(X_train_full, y_train_full, X_test, y_test):\n",
        "    X_train, X_val, y_train, y_val = get_validation(X_train_full, y_train_full)\n",
        "\n",
        "    kernels = ['linear', 'poly', 'rbf']\n",
        "    C_values = [0.01, 0.1, 1, 10, 100]\n",
        "    best_kernel = ''\n",
        "    best_C = -1\n",
        "    best_acc = 0\n",
        "\n",
        "    accs = {}\n",
        "    for kernel in kernels:\n",
        "        accs[kernel] = []\n",
        "    for kernel, c in tqdm(itertools.product(kernels, C_values), leave=False):\n",
        "        model = SVC(kernel=kernel, C=c)\n",
        "        model.fit(X_train, y_train)\n",
        "        acc = model.score(X_val, y_val)\n",
        "        accs[kernel].append(acc)\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_C = c\n",
        "            best_kernel = kernel\n",
        "    \n",
        "    best_accs = [max(accs[kernel]) for kernel in kernels]\n",
        "    plt.bar(kernels, best_accs)\n",
        "    plt.xticks(list(range(len(best_accs))), kernels)\n",
        "    plt.show()\n",
        "    print(f'Optimal kernel: {best_kernel}')\n",
        "\n",
        "    model = SVC(kernel=best_kernel, C=best_C)\n",
        "    model.fit(X_train_full, y_train_full)\n",
        "\n",
        "    return model.predict(X_test), model.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPCS7NeYjxn1"
      },
      "source": [
        "## Dense Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7uKqh78ospP"
      },
      "outputs": [],
      "source": [
        "def load_torch_data(X_train, y_train, X_test, y_test):\n",
        "    X_train, X_val, y_train, y_val = get_validation(X_train, y_train)\n",
        "    train_set = data.TensorDataset(Tensor(X_train), Tensor(y_train))\n",
        "    val_set = data.TensorDataset(Tensor(X_val), Tensor(y_val))\n",
        "    test_set = data.TensorDataset(Tensor(X_test), Tensor(y_test))\n",
        "    train_loader = data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "    val_loader = data.DataLoader(val_set, batch_size=32, shuffle=True)\n",
        "    test_loader = data.DataLoader(test_set, batch_size=32, shuffle=True)\n",
        "    return train_loader, val_loader, test_loader\n",
        "    \n",
        "\n",
        "def train_network(model, train_loader, val_loader, epochs, lr):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr) \n",
        "\n",
        "    train_loss = []\n",
        "    train_acc = []\n",
        "    val_acc = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0\n",
        "        for itr, (image, label) in tqdm(enumerate(train_loader), total=len(train_loader), leave=False):\n",
        "            optimizer.zero_grad()\n",
        "            y_predicted = model(image)\n",
        "            label = label.long()\n",
        "\n",
        "            loss = criterion(y_predicted, label)\n",
        "            running_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    \n",
        "        train_loss.append(running_loss)\n",
        "        train_acc.append(evaluate_network(model, train_loader)[-1])\n",
        "        val_acc.append(evaluate_network(model, val_loader)[-1])\n",
        "        print(f'Epoch: {epoch+1:03}, Loss: {running_loss:9.4f}, Train Accuracy: {train_acc[-1]:.4f}, Validation Accuracy: {val_acc[-1]:.4f}')\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
        "    axs[0].plot(train_loss)\n",
        "    axs[1].plot(list(range(epochs)), train_acc, val_acc);\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate_network(model, dataloader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    y_pred = []\n",
        "    y_pred = torch.Tensor()\n",
        "    with torch.no_grad():\n",
        "        for itr, (image, label) in enumerate(dataloader):\n",
        "            outputs = model(image)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            y_pred = torch.cat((y_pred, predicted))\n",
        "            correct += predicted.eq(label.reshape(len(label),)).sum() \n",
        "            total += float(len(label))\n",
        "        accuracy = correct / total\n",
        "        return y_pred.tolist(), accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXZT0kN1c0JU"
      },
      "outputs": [],
      "source": [
        "class NN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(32 * 32 * 3, 128)\n",
        "        self.layer2 = nn.Linear(128, 64)\n",
        "        self.out_layer = nn.Linear(64, K)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.relu(self.layer2(x))\n",
        "        x = self.out_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsattGC-jzYw"
      },
      "source": [
        "## Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CB0H8YxKTnl"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.conv_1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm_1 = nn.BatchNorm2d(32)\n",
        "        self.conv_2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
        "        self.conv_3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
        "        self.conv_4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm_4 = nn.BatchNorm2d(64)\n",
        "        self.dropout_1 = nn.Dropout(0.5)\n",
        "        self.conv_5 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm_5 = nn.BatchNorm2d(64)\n",
        "        self.conv_6 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch_norm_6 = nn.BatchNorm2d(64)\n",
        "        self.dropout_2 = nn.Dropout(0.5)\n",
        "        self.linear_1 = nn.Linear(4 * 4 * 64, 128)\n",
        "        self.dropout_3 = nn.Dropout(0.25)\n",
        "        self.linear_2 = nn.Linear(128, K)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.batch_norm_1(self.conv_1(x)))\n",
        "        x = self.relu(self.batch_norm_2(self.conv_2(x)))\n",
        "        x = self.max_pool2d(x)\n",
        "        x = self.relu(self.batch_norm_3(self.conv_3(x)))\n",
        "        x = self.relu(self.batch_norm_4(self.conv_4(x)))\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.max_pool2d(x)\n",
        "        x = self.relu(self.batch_norm_5(self.conv_5(x)))\n",
        "        x = self.relu(self.batch_norm_6(self.conv_6(x)))\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.max_pool2d(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.relu(self.linear_1(x))\n",
        "        x = self.dropout_3(x)\n",
        "        x = self.linear_2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI9lT-q-kteU"
      },
      "source": [
        "## Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCCV5sIrH-Rq"
      },
      "outputs": [],
      "source": [
        "def Resnet():\n",
        "    model = torchvision.models.resnet18(pretrained=True)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, K)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Xq-iQwNfbKq"
      },
      "outputs": [],
      "source": [
        "def VGG16():\n",
        "    model = torchvision.models.vgg16(pretrained=True)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    num_ftrs = model.classifier[-1].in_features\n",
        "    model.classifier[-1] = nn.Linear(num_ftrs, K)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDWWGFp6kW8c"
      },
      "outputs": [],
      "source": [
        "def EfficientNet():\n",
        "    model = torchvision.models.efficientnet_b0(pretrained=True)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    num_ftrs = model.classifier[-1].in_features\n",
        "    model.classifier[-1] = nn.Linear(num_ftrs, K)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UpscaleDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, transform):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.numpy()\n",
        "        img = self.transform(torch.from_numpy(self.X[idx].astype(np.float32)))\n",
        "        label = torch.tensor(self.y[idx])\n",
        "\n",
        "        return img, label\n",
        "\n",
        "\n",
        "def load_vit_data(X_train, y_train, X_test, y_test):\n",
        "    X_train, X_val, y_train, y_val = get_validation(X_train, y_train)\n",
        "    transform = torchvision.transforms.Resize((224, 224))\n",
        "    train_set = UpscaleDataset(X_train, y_train, transform)\n",
        "    val_set = UpscaleDataset(X_val, y_val, transform)\n",
        "    test_set = UpscaleDataset(X_test, y_test, transform)\n",
        "    train_loader = data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "    val_loader = data.DataLoader(val_set, batch_size=32, shuffle=True)\n",
        "    test_loader = data.DataLoader(test_set, batch_size=32, shuffle=True)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def VisionTransformer():\n",
        "    model = torchvision.models.vit_b_16(pretrained=True)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    num_ftrs = model.heads[-1].in_features\n",
        "    model.heads[-1] = nn.Linear(num_ftrs, K)\n",
        "    return model"
      ],
      "metadata": {
        "id": "RxTjUA2PYJoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLYfefMU_GtW"
      },
      "source": [
        "# Training and Evaluation\n",
        "We now run all the models defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulTw4pvxCNnZ"
      },
      "outputs": [],
      "source": [
        "def generateConfusionMatrix(y_actual, y_pred):\n",
        "    mat = confusion_matrix(y_actual, y_pred)\n",
        "    plt.figure(figsize = (30, 30))\n",
        "    sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False, xticklabels = labels['Name'], yticklabels = labels['Name'])\n",
        "    plt.xlabel('true label')\n",
        "    plt.ylabel('predicted label')\n",
        " \n",
        " \n",
        "def classificationReport(y_actual, y_pred, print_df=False):\n",
        "    # Get classification report from sklearn package as python dict\n",
        "    report = classification_report(y_actual, y_pred, target_names = labels['Name'], output_dict = True)\n",
        "    \n",
        "    # Get per class accuracies\n",
        "    mat = confusion_matrix(y_actual, y_pred)\n",
        "    class_accuracies = mat.diagonal()/(mat.sum(axis = 1))\n",
        "    for index, class_name in enumerate(labels['Name']):\n",
        "        report[class_name]['accuracy'] = class_accuracies[index]\n",
        "\n",
        "    df = pd.DataFrame.from_dict(report).T\n",
        "    if print_df:\n",
        "        print(tabulate(df, headers = ['Label', 'Precision', 'Recall', 'F1 Score', 'Support', 'Accuracy'], tablefmt = 'fancy_grid'))\n",
        "\n",
        "    return report, df\n",
        "\n",
        "\n",
        "def generate_class_comparison(report, metric):\n",
        "    classes = list(labels['Name'])\n",
        "    values = [report[cls][metric] for cls in classes]\n",
        "    plt.xticks([], [])\n",
        "    plt.bar(classes, values)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcuHmemjqoLg"
      },
      "outputs": [],
      "source": [
        "print('========== Logistic Regression (PCA) ==========')\n",
        "y_pred_log, acc = logistic_regression(X_train_pca, y_train, X_test_pca, y_test)\n",
        "print(f'Test Accuracy: {acc}')\n",
        "log_report, log_df = classificationReport(y_test, y_pred_log)\n",
        "generate_class_comparison(log_report, 'f1-score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvxEFB-3iciz"
      },
      "outputs": [],
      "source": [
        "print('========== KNN ==========')\n",
        "y_pred_knn, acc = knn(X_train_flattened, y_train, X_test_flattened, y_test)\n",
        "print(f'Test Accuracy: {acc}')\n",
        "knn_reportdict, knn_df = classificationReport(y_test, y_pred_knn)\n",
        "generate_class_comparison(knn_reportdict, 'f1-score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6g8G3SdJ_LZv"
      },
      "outputs": [],
      "source": [
        "print('========== KNN (PCA) ==========')\n",
        "y_pred_knnpca, acc = knn(X_train_pca, y_train, X_test_pca, y_test)\n",
        "print(f'Test Accuracy: {acc}')\n",
        "knnpca_reportdict, knnpca_df = classificationReport(y_test, y_pred_knnpca)\n",
        "generate_class_comparison(knnpca_reportdict, 'f1-score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_N92jyr_QG0"
      },
      "outputs": [],
      "source": [
        "print('========== Adaboost (PCA) ==========')\n",
        "y_pred_ada, acc = adaboost(X_train_pca, y_train, X_test_pca, y_test)\n",
        "print(f'Test Accuracy: {acc}')\n",
        "ada_reportdict, ada_df = classificationReport(y_test, y_pred_ada)\n",
        "generate_class_comparison(ada_reportdict, 'f1-score')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('========== XGBoost (PCA) ==========')\n",
        "y_pred_xgb, acc = xgboost(X_train_pca, y_train, X_test_pca, y_test)\n",
        "print(f'Test Accuracy: {acc}')\n",
        "xbg_reportdict, xbg_df = classificationReport(y_test, y_pred_xgb)\n",
        "generate_class_comparison(xgb_reportdict, 'f1-score')"
      ],
      "metadata": {
        "id": "6Qfi7EfEZKgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAElP9LLniup"
      },
      "outputs": [],
      "source": [
        "print('========== Kernelized SVM (PCA) ==========')\n",
        "y_pred_svm, acc = kernel_svm(X_train_pca, y_train, X_test_pca, y_test)\n",
        "print(f'Test Accuracy: {acc}')\n",
        "svm_reportdict, svm_df = classificationReport(y_test, y_pred_svm)\n",
        "generate_class_comparison(svm_reportdict, 'f1-score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-ANqgbYpuf8"
      },
      "outputs": [],
      "source": [
        "print('========== Dense Neural Network ==========')\n",
        "train_loader, val_loader, test_loader = load_torch_data(X_train_flattened, y_train, X_test_flattened, y_test)\n",
        "model = train_network(NN(), train_loader, val_loader, 10, 1e-3)\n",
        "y_pred_nn, acc = evaluate_network(model, test_loader)\n",
        "print(f'Test Accuracy: {acc}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MpYJcA1QO1L"
      },
      "outputs": [],
      "source": [
        "nn_reportdict, nn_df = classificationReport(y_test, y_pred_nn)\n",
        "generate_class_comparison(nn_reportdict, 'f1-score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TW26cz3ipNWi"
      },
      "outputs": [],
      "source": [
        "print('========== Convolutional Neural Network ==========')\n",
        "train_loader, val_loader, test_loader = load_torch_data(X_train, y_train, X_test, y_test)\n",
        "model = train_network(CNN(), train_loader, val_loader, 10, 1e-3)\n",
        "y_pred_cnn, accuracy = evaluate_network(model, test_loader)\n",
        "print(f'Test Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxZxBp3VQTzF"
      },
      "outputs": [],
      "source": [
        "cnn_reportdict, cnn_df = classificationReport(y_test, y_pred_cnn)\n",
        "generate_class_comparison(cnn_reportdict, 'f1-score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJHgtXPfJD_G"
      },
      "outputs": [],
      "source": [
        "print('========== Transfer Learning Resnet ==========')\n",
        "train_loader, val_loader, test_loader = load_torch_data(X_train, y_train, X_test, y_test)\n",
        "model = train_network(Resnet(), train_loader, val_loader, 10, 1e-3)\n",
        "y_pred_res, accuracy = evaluate_network(model, test_loader)\n",
        "print(f'Test Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uJASPUhQVCs"
      },
      "outputs": [],
      "source": [
        "res_reportdict, res_df = classificationReport(y_test, y_pred_res)\n",
        "generate_class_comparison(res_reportdict, 'f1-score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IY5y1LM7fhqh"
      },
      "outputs": [],
      "source": [
        "print('========== Transfer Learning VGG16 ==========')\n",
        "train_loader, val_loader, test_loader = load_torch_data(X_train, y_train, X_test, y_test)\n",
        "model = train_network(VGG16(), train_loader, val_loader, 10, 1e-3)\n",
        "y_pred_vgg, accuracy = evaluate_network(model, test_loader)\n",
        "print(f'Test Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyAEA0qTQWrZ"
      },
      "outputs": [],
      "source": [
        "vgg_reportdict, vgg_df = classificationReport(y_test, y_pred_vgg)\n",
        "generate_class_comparison(vgg_reportdict, 'f1-score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cANkVqwmbCz"
      },
      "outputs": [],
      "source": [
        "print('========== Transfer Learning EfficientNet ==========')\n",
        "train_loader, val_loader, test_loader = load_torch_data(X_train, y_train, X_test, y_test)\n",
        "model = train_network(EfficientNet(), train_loader, val_loader, 10, 1e-3)\n",
        "y_pred_eff, accuracy = evaluate_network(model, test_loader)\n",
        "print(f'Test Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZOU_KOTQXx0"
      },
      "outputs": [],
      "source": [
        "eff_reportdict, eff_df = classificationReport(y_test, y_pred_eff)\n",
        "generate_class_comparison(eff_reportdict, 'f1-score')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('========== Transfer Learning Vision Transformer ==========')\n",
        "train_loader, val_loader, test_loader = load_vit_data(X_train, y_train, X_test, y_test)\n",
        "model = train_network(VisionTransformer(), train_loader, val_loader, 10, 1e-3)\n",
        "y_pred_vit, accuracy = evaluate_network(model, test_loader)\n",
        "print(f'Test Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "Go4AAClYYQ2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_reportdict, vit_df = classificationReport(y_test, y_pred_vit)\n",
        "generate_class_comparison(vit_reportdict, 'f1-score')"
      ],
      "metadata": {
        "id": "MSXj0LW7YUxp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}