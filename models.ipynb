{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRrDti8n2Vw8"
      },
      "outputs": [],
      "source": [
        "# Download dataset from github repo\n",
        "!rm -r sample_data\n",
        "!git clone https://github.com/willjhliang/traffic-sign-recognition.git\n",
        "!mv traffic-sign-recognition/data .\n",
        "!rm -r traffic-sign-recognition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from copy import deepcopy\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, KFold"
      ],
      "metadata": {
        "id": "bDwc2e3-4pvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K = 58  # Number of classes\n",
        "S = 32  # Size of image, dimension is (s, s, 3)\n",
        "\n",
        "random_seed = 19104"
      ],
      "metadata": {
        "id": "8auRbcGP5jJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration"
      ],
      "metadata": {
        "id": "MjD_ep2c5HUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(datapath):\n",
        "    data = {}\n",
        "    for k in range(K):\n",
        "        data[k] = []\n",
        "    for f in os.listdir(datapath):\n",
        "        k = int(f[:3])\n",
        "        img = Image.open(os.path.join(datapath, f)).convert('L')\n",
        "        img = np.asarray(img) / 255\n",
        "        data[k].append(img)\n",
        "    return data"
      ],
      "metadata": {
        "id": "Gr29Pwh625Jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = pd.read_csv(\"data/labels.csv\")\n",
        "\n",
        "train_data = load_data('data/images/train')\n",
        "test_data = load_data('data/images/test')"
      ],
      "metadata": {
        "id": "Br0-GXCA4rts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.gray()\n",
        "fig, axs = plt.subplots(6, 10)\n",
        "fig.set_figheight(15)\n",
        "fig.set_figwidth(15)\n",
        "for k, (i, j) in itertools.zip_longest(range(K), list(itertools.product(range(6), range(10))), fillvalue=-1):\n",
        "    axs[i,j].axis('off')\n",
        "    if k >= 0:\n",
        "        axs[i,j].imshow(train_data[k][0])\n"
      ],
      "metadata": {
        "id": "MeVxBPI864JY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_dist = plt.bar(list(range(K)), [len(train_data[k]) for k in range(K)])"
      ],
      "metadata": {
        "id": "w3rniKpZ9gNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def center_crop(img, center_percentage):\n",
        "    width, height = img.shape\n",
        "    width_offset = int(width * (1 - center_percentage) / 2)\n",
        "    height_offset = int(height * (1 - center_percentage) / 2)\n",
        "    img = img[width_offset:width-width_offset, height_offset:height-height_offset]\n",
        "    return img\n",
        "\n",
        "def rotate_img(img, angle):\n",
        "    height, width = img.shape\n",
        "    center_x, center_y = (width // 2, height // 2)\n",
        "\n",
        "    rot_mat = cv2.getRotationMatrix2D((center_x, center_y), angle, 1.0)\n",
        "    cos = np.abs(rot_mat[0, 0])\n",
        "    sin = np.abs(rot_mat[0, 1])\n",
        "\n",
        "    new_width = int((height * sin) + (width * cos))\n",
        "    new_height = int((height * cos) + (width * sin))\n",
        "    rot_mat[0, 2] += (new_width / 2) - center_x\n",
        "    rot_mat[1, 2] += (new_height / 2) - center_y\n",
        "\n",
        "    img = cv2.warpAffine(img, rot_mat, (new_width, new_height))\n",
        "    img = cv2.resize(img, (width, height))\n",
        "\n",
        "    return img\n",
        "\n",
        "def shift_brightness(img, shift):\n",
        "    img = np.clip(img + shift, 0, 255)\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "ETRb3zMX869y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "\n",
        "def augment_img(img):\n",
        "    rot_angle = randint(-30, 30)\n",
        "    crop_center_percentage = randint(70, 90) / 100\n",
        "    crop_center_percentage = 0.8\n",
        "    brightness_shift = randint(-20, 20) / 100\n",
        "    img = rotate_img(img, rot_angle)\n",
        "    img = center_crop(img, crop_center_percentage)\n",
        "    img = shift_brightness(img, brightness_shift)\n",
        "    img = center_crop(img, 0.8)\n",
        "    return img"
      ],
      "metadata": {
        "id": "D0LV8uZsCB0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "largest_class_size = max([len(train_data[k]) for k in range(K)])\n",
        "for k in range(K):\n",
        "    size_diff = largest_class_size - len(train_data[k])\n",
        "    for i in range(size_diff):\n",
        "        train_data[k].append(augment_img(train_data[k][i % len(train_data[k])]))"
      ],
      "metadata": {
        "id": "UG-NpBFR8hgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_dist = plt.bar(list(range(K)), [len(train_data[k]) for k in range(K)])"
      ],
      "metadata": {
        "id": "nt5sG5QiHtzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(data):\n",
        "    X = []\n",
        "    y = []\n",
        "    for k in range(K):\n",
        "        for i in data[k]:\n",
        "            X.append(cv2.resize(i, (S, S)))\n",
        "            y.append(k)\n",
        "    \n",
        "    X_flattened = deepcopy(X)\n",
        "    for i in range(len(X_flattened)):\n",
        "        X_flattened[i] = X_flattened[i].flatten()\n",
        "    \n",
        "    X = np.array(X)\n",
        "    X_flattened = np.array(X_flattened)\n",
        "    y = np.array(y)\n",
        "    return X, X_flattened, y"
      ],
      "metadata": {
        "id": "4UVlLK8c3HXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_train_flattened, y_train = prepare_data(train_data)\n",
        "X_test, X_test_flattened, y_test = prepare_data(test_data)"
      ],
      "metadata": {
        "id": "MTT4G6q63fp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models\n",
        "\n",
        "The following is a set of models we run on the data. Starting with the most simple baseline K-Nearest Neighbors, we move toward more complex models.\n",
        "1. Baseline KNN\n",
        "2. Adaboost\n",
        "3. Logistic Regression\n",
        "4. Kernelized SVM\n",
        "5. Dense Neural Network\n",
        "6. Convolutional Neural Network\n",
        "\n",
        "We also test two more advanced strategies.\n",
        "1. Autoencoder dimensionality reduction allows us to embed the images in a lower dimensional space, which may lead to stronger classification performance by simpler models.\n",
        "2. Transfer learning with a CNN allows us to adapt weights from pre-trained networks to our traffic sign recognition problem."
      ],
      "metadata": {
        "id": "zUuXolGt5JZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline KNN"
      ],
      "metadata": {
        "id": "7WmDtprV5NqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a baseline K-Nearest Neighbors models to classify traffic sign images. Use 10-Fold cross validation to determine the best value of K"
      ],
      "metadata": {
        "id": "NCtWS2CqGgpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def knnBaseline(X_train, y_train, X_test, y_test):\n",
        "    kf = KFold(n_splits = 10)\n",
        "    best_k = -1\n",
        "    best_acc = 0\n",
        "    val_accuracies = []\n",
        "\n",
        "    # Iterate through possible values of k from 1 to 30, incrementing by 2\n",
        "    for k_neighbors in range(1, 30, 2):\n",
        "        for train_index, val_index in kf.split(X_train): # Iterate through all 10 folds\n",
        "            total_acc = 0\n",
        "            # Split data into training data and validation data\n",
        "            X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "            y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "            # Train KNN model\n",
        "            knn_model = KNeighborsClassifier(n_neighbors=k_neighbors)\n",
        "            knn_model.fit(X_train_fold, y_train_fold)\n",
        "            total_acc = total_acc + knn_model.score(X_val_fold, y_val_fold)\n",
        "        \n",
        "        # Get avg accuracy for the folds for this k value\n",
        "        avg_acc = total_acc / 10\n",
        "        val_accuracies.append(avg_acc)\n",
        "        if avg_acc > best_acc:\n",
        "            best_acc = avg_acc\n",
        "            best_k = k_neighbors\n",
        "\n",
        "    # Plot to show the best values\n",
        "    plt.plot(list(range(1, 30, 2)), val_accuracies)\n",
        "    plt.show()\n",
        "    print(\"Best k: \", best_k)\n",
        "\n",
        "    # Fit model with the best k value\n",
        "    model = KNeighborsClassifier(n_neighbors=best_k)\n",
        "    model.fit(X_train_flattened, y_train)\n",
        "    \n",
        "    # Accurcay on the test set\n",
        "    return model.score(X_test_flattened, y_test)\n"
      ],
      "metadata": {
        "id": "GokJxe4KGJz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(knnBaseline(X_train_flattened, y_train, X_test_flattened, y_test))"
      ],
      "metadata": {
        "id": "yGrcavdS2WX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adaboost"
      ],
      "metadata": {
        "id": "M1sX4gyWji8A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "fgSsZgmhjr5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kernelized SVM"
      ],
      "metadata": {
        "id": "kBUqSumgjuwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dense Neural Network"
      ],
      "metadata": {
        "id": "UPCS7NeYjxn1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Network"
      ],
      "metadata": {
        "id": "xsattGC-jzYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoencoder Dimensionality Reduction"
      ],
      "metadata": {
        "id": "DGWm6fptj051"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adaboost"
      ],
      "metadata": {
        "id": "KQy6vySzkBKG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "-HSnHQVsj9Jl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kernelized SVM"
      ],
      "metadata": {
        "id": "tTSK437qj_dZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning with CNN"
      ],
      "metadata": {
        "id": "jI9lT-q-kteU"
      }
    }
  ]
}